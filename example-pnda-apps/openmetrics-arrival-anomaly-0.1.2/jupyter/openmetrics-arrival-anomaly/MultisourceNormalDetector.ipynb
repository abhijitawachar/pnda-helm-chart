{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "normal_quantiles_zp = {\n",
    "    0.8: 1.281551565545,\n",
    "    0.9: 1.644853626951,\n",
    "    0.95: 1.959963984540,\n",
    "    0.98: 2.326347874041,\n",
    "    0.99: 2.575829303549,\n",
    "    0.995: 2.807033768344,\n",
    "    0.998: 3.090232306168,\n",
    "    0.999: 3.290526731492,\n",
    "    0.9999: 3.890591886413,\n",
    "    0.99999: 4.417173413469,\n",
    "    0.999999: 4.891638475699,\n",
    "    0.9999999: 5.326723886384,\n",
    "    0.99999999: 5.730728868236,\n",
    "    0.999999999: 6.109410204869,\n",
    "}\n",
    "\n",
    "# Define the model class\n",
    "#class MultisourceNormalDetector(mlflow.pyfunc.PythonModel):\n",
    "class MultisourceNormalDetector:\n",
    "    def __init__(self):\n",
    "        self.stats = {}\n",
    "\n",
    "    \n",
    "    def fit(self, input: pd.DataFrame):\n",
    "        # Non-incremental avg-var computation. Stats are reset\n",
    "        self.reset()\n",
    "        agg_df = input.groupby(['source'])['value'].agg(['sum','count','var'])\n",
    "        for source,row in agg_df.iterrows():\n",
    "            stats = {'sum': row['sum'],\n",
    "                        'count': row['count'],\n",
    "                        'avg': row['sum']/row['count'],\n",
    "                        'var': row['var']}\n",
    "            self.stats[source] = stats\n",
    "\n",
    "    def incremental_fit(self, input: pd.DataFrame):\n",
    "        # incremental avg-var computation\n",
    "        # https://math.stackexchange.com/questions/102978/incremental-computation-of-standard-deviation\n",
    "        for index,row in input.iterrows():\n",
    "            stats = self.stats.get(row['source'],{'sum':0,'count':0, 'var':0})\n",
    "            sum = stats['sum'] + row['value']\n",
    "            count = stats['count'] + 1\n",
    "            if count > 1:\n",
    "                stats['var'] = (count-2)/(count-1) * stats['var'] + 1/count * math.pow((row['value'] - stats['avg']),2)\n",
    "            else:\n",
    "                stats['var'] = stats['var'] + math.pow(row['value']- sum/count,2)\n",
    "            stats['avg'] = sum/count\n",
    "            stats['sum'] = sum\n",
    "            stats['count'] = count\n",
    "            self.stats[row['source']] = stats\n",
    "\n",
    "    def reset(self,source=None):\n",
    "        if source:\n",
    "            self.stats[source] = {}\n",
    "        else:\n",
    "            self.stats = {}\n",
    "\n",
    "\n",
    "    def predict(self, context, model_input: pd.DataFrame, p=0.99999) -> pd.DataFrame:\n",
    "        #NOTE can be optimized using pandas to perform this condition check\n",
    "        output = []\n",
    "        for index,row in model_input.iterrows():  \n",
    "            source = row['source']\n",
    "            value = row['value']\n",
    "            timestamp = row['timestamp']\n",
    "            if source not in self.stats:\n",
    "                output_row = [source, str(timestamp), value, True, 'unknown source']\n",
    "            else:\n",
    "                stats = self.stats[source]\n",
    "                zp = normal_quantiles_zp[p]\n",
    "                diff = zp*math.sqrt(stats['var'])\n",
    "                min = stats['avg'] - diff\n",
    "                max = stats['avg'] + diff\n",
    "                if min <= value <= max:\n",
    "                    output_row = [source, str(timestamp), value, False, None]\n",
    "                else:\n",
    "                    output_row = [source, str(timestamp), value, True, 'value out of limits ({},{})'.format(min,max)]\n",
    "            output.append(output_row)\n",
    "        return pd.DataFrame(output, \n",
    "                 columns= ['source','timestamp','value','anomaly','anomaly_type'])\n",
    "        for index,row in model_input.iterrows():  \n",
    "            source = row['source']\n",
    "            value = row['value']\n",
    "            timestamp = row['timestamp']\n",
    "            if source not in self.stats:\n",
    "                output_row = [source, str(timestamp), value, True, 'unknown source']\n",
    "            else:\n",
    "                stats = self.stats[source]\n",
    "                zp = normal_quantiles_zp[p]\n",
    "                diff = zp*math.sqrt(stats['variance'])\n",
    "                min = stats['avg'] - diff\n",
    "                max = stats['avg'] + diff\n",
    "                if min <= value <= max:\n",
    "                    output_row = [source, str(timestamp), value, False, None]\n",
    "                else:\n",
    "                    output_row = [source, str(timestamp), value, True, 'value out of limits ({},{})'.format(min,max)]\n",
    "            output.append(output_row)\n",
    "        return pd.DataFrame(output, \n",
    "                 columns= ['source','timestamp','value','anomaly','anomaly_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-incremental fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interarrival_df = pd.read_csv('normal_interarrival_samples.csv')\n",
    "\n",
    "model = MultisourceNormalDetector()\n",
    "model.fit(interarrival_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "input_df = interarrival_df\n",
    "output_df = model.predict(context=None, model_input=input_df)\n",
    "print(output_df[output_df.anomaly == True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "input_df = pd.read_csv('normal_interarrival_samples_with_anomalies.csv')\n",
    "output_df = model.predict(context=None, model_input=input_df)\n",
    "print(output_df[output_df.anomaly == True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interarrival_df = pd.read_csv('normal_interarrival_samples.csv')\n",
    "model.reset()\n",
    "model = MultisourceNormalDetector()\n",
    "model.incremental_fit(interarrival_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "input_df = interarrival_df\n",
    "output_df = model.predict(context=None, model_input=input_df)\n",
    "print(output_df[output_df.anomaly == True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "input_df = pd.read_csv('normal_interarrival_samples_with_anomalies.csv')\n",
    "output_df = model.predict(context=None, model_input=input_df)\n",
    "print(output_df[output_df.anomaly == True])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
